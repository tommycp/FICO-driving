{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical EDA\n",
    "\n",
    "In this section of the notebook we will be using statistics and other measures of data to examine the data for interesting trends, occurences, and relationships. First, we will explore using univariate statistics, but we plan to investigate multivariate relationships as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Helper functions for EDA\n",
    "def isnotnan(x):\n",
    "    return not math.isnan(x)\n",
    "\n",
    "def dropna(x):\n",
    "    return list(filter(lambda x: x > -np.inf, x))\n",
    "\n",
    "def describe(x_):\n",
    "    x = dropna(x_)\n",
    "    if len(x) == 0: print(\"No description available for this data as there are no non-NaN values present.\"); return\n",
    "    n = sum(map(isnotnan, x))\n",
    "    print ('N: \\t\\t\\t{}\\nRange: \\t\\t\\t[{:.4}  -:-  {:.4}]\\nMean: \\t\\t\\t{:.4}\\nStandard Deviation: \\t{:.4}'.format(n, min(x), max(x), np.mean(x), np.std(x)))\n",
    "\n",
    "def min_diff(x):\n",
    "    if (len(x)) == 1: return 0\n",
    "    return min((x[i + 1] - x[i] for i in range(len(x) - 1)))\n",
    "    \n",
    "def _is_int(x):\n",
    "    for i in range(len(x) - 1):\n",
    "        if (x[i + 1] - x[i]) != 1: return False\n",
    "    return True\n",
    "        \n",
    "def granularity(x):\n",
    "    span = max(x) - min(x)\n",
    "    if (span == 0): return 0 # No real definiton of granularity if there is only one unique value, essentially 0. \n",
    "    \n",
    "    g = min_diff(x)\n",
    "    \n",
    "    if g == 1: \n",
    "        if _is_int: return 'integer'\n",
    "    if (g / span <= 2**-16): # If it requires more than 16 bits of information to encode the data and is not an integer,\n",
    "        return 'real'        # we assume it is a real number\n",
    "    return '{:.4}'.format(g)\n",
    "    \n",
    "def unique(x_, force_print = False):\n",
    "    x = dropna(x_)\n",
    "    if len(x) == 0: print(\"No uniqueness information available for this data as there are no non-NaN values present.\"); return\n",
    "    \n",
    "    uniques = pd.Series(x).unique(); uniques.sort()\n",
    "    g = granularity(uniques)\n",
    "    n = len(uniques)\n",
    "    \n",
    "    print('N unique: \\t\\t\\t{}\\nGranularity (estimated): \\t {}'.format(n, g))\n",
    "    if n <= 100 or force_print: print(uniques)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path = 'data/VehicleID_152851_DriverID_22209/VehicleID_152851_DriverID_22209/File_ID_1229.csv'\n",
    "data = pd.read_csv(path, na_values=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0              NaN\n",
       "1              NaN\n",
       "2              NaN\n",
       "3              NaN\n",
       "4              NaN\n",
       "5              NaN\n",
       "6              NaN\n",
       "7              NaN\n",
       "8              NaN\n",
       "9              NaN\n",
       "10             NaN\n",
       "11             NaN\n",
       "12             NaN\n",
       "13             NaN\n",
       "14             NaN\n",
       "15             NaN\n",
       "16             NaN\n",
       "17             NaN\n",
       "18             NaN\n",
       "19             NaN\n",
       "20        0.000000\n",
       "21             NaN\n",
       "22             NaN\n",
       "23             NaN\n",
       "24             NaN\n",
       "25             NaN\n",
       "26             NaN\n",
       "27             NaN\n",
       "28             NaN\n",
       "29      631.443896\n",
       "           ...    \n",
       "2093    334.771411\n",
       "2094    334.771411\n",
       "2095    334.771411\n",
       "2096    334.771411\n",
       "2097    334.771411\n",
       "2098    334.771411\n",
       "2099    334.771411\n",
       "2100    334.771411\n",
       "2101    334.771411\n",
       "2102    334.771411\n",
       "2103    334.771411\n",
       "2104    334.771411\n",
       "2105    334.771411\n",
       "2106    334.771411\n",
       "2107    334.771411\n",
       "2108    334.771411\n",
       "2109    334.771411\n",
       "2110    334.771411\n",
       "2111    334.771411\n",
       "2112    334.771411\n",
       "2113    334.771411\n",
       "2114    334.771411\n",
       "2115    334.771411\n",
       "2116    334.771411\n",
       "2117    334.771411\n",
       "2118    334.771411\n",
       "2119    334.771411\n",
       "2120    334.771411\n",
       "2121    334.771411\n",
       "2122           NaN\n",
       "Name: vtti.lane_width, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col = data['vtti.lane_width']\n",
    "col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N: \t\t\t1933\n",
      "Range: \t\t\t[0.0  -:-  748.3]\n",
      "Mean: \t\t\t372.3\n",
      "Standard Deviation: \t113.0\n"
     ]
    }
   ],
   "source": [
    "describe(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N unique: \t\t\t859\n",
      "Granularity (estimated): \t real\n"
     ]
    }
   ],
   "source": [
    "unique(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical EDA discoveries:\n",
    "\n",
    "### vtti.file_id\n",
    "* Consistent for file, can be dropped to save RAM and only include relevant data. Purely an ID/key.\n",
    "* CAN BE DROPPED\n",
    "\n",
    "### vtti.abs\n",
    "* No non-zero, non-nan values for files 1308 or 1229\n",
    "\n",
    "### vtti.alcohol_interior\n",
    "* Average value is ~4082, range of (4050, 4095)\n",
    "\n",
    "### vtti.accel (\\_x, \\_y, \\_z)\n",
    "* All have same amount of nans (87), this is comforting\n",
    "    * Should be something that we check and enforce if we use accelerometer readings.\n",
    "* Could/should be consolidated?\n",
    "    \n",
    "### vtti.cruise_state\n",
    "* No non-zero, non-nan values for file 1308\n",
    "    * Perhaps a driver's usage of cruis control could suggest something about the safety of their driving habits?\n",
    "    \n",
    "### computed.day_of_month\n",
    "* All non-nan values are 6 (the only value present among a sea of NaNs in the column)\n",
    "    * Indicates that all values will be the same for all csvs in this format, should be verified regardless.\n",
    "* CAN BE DROPPED\n",
    "\n",
    "### vtti.driver_button\n",
    "* Not used in either file that Tommy has access to.\n",
    "    * ergo we don't have crash validation data\n",
    "\n",
    "### vtti.elevation_gps\n",
    "* Used 1321/13507 in file 1308\n",
    "    * Suggests roughly 1/10 the frequency of acceleration data.\n",
    "    \n",
    "### vtti.engine_rpm\n",
    "* Only 21 nan values!\n",
    "* Can be compared to throttle\n",
    "\n",
    "### vtti.esc\n",
    "* Only 21 nan values\n",
    "* No non-zero non-nan values\n",
    "* No idea what this variable is, possibly the automatic event detection (automated version of driver button)\n",
    "\n",
    "### vtti.gyro (\\_x, \\_y, \\_z)\n",
    "* 1356 nan values\n",
    "    * Seems to be same frequency as acceleration data, but with more drops\n",
    "    * Could smoothly extrapolate these data points fairly easily (no meaning lost)\n",
    "    \n",
    "### vtti.head_confidence\n",
    "* 1833 nan values\n",
    "* Integer, ranges from 0 to 235, mean of 145 and sd of 70\n",
    "    * Confidence is likely relative to itself\n",
    "        * Will require determining max possible value and scaling this down to a probability\n",
    "    * Suspect that this can be fit into 8 bits (and may even be 8 bits for vtti) as values are likely 0-255 and are definitely integer.\n",
    "        \n",
    "\n",
    "### vtti.head_position (\\_x, \\_y, \\_z)\n",
    "* 1833 nan values\n",
    "    * Good that it matches the confidence, should be verified.\n",
    "* Integer values, likely mapping the center of the head in pixels.\n",
    "    \n",
    "### vtti.head\\_position\\_~\\_baseline (where ~ is x, y, or z)\n",
    "* 14 values\n",
    "* BASELINE VARIES, will be necessary to consider these variations in order to get accurate relative location data. Maybe.\n",
    "* Hypotheses about variations:\n",
    "    * The baseline resets after a set amount of time\n",
    "        * Incorrect since indices of resets are NOT at even intervals in the index, which directly correlates to realtime.\n",
    "    * The baseline resets when the driver adjusts too much\n",
    "        * Would require video confirmation\n",
    "        * Could be investigated by examining the amount of spread in the head's location prior to a reset, and comparing this spread to the average spread during the segment between resets.\n",
    "            \n",
    "### vtti.head_rotation (\\_x, \\_y, \\_z)\n",
    "* 1833 nan values\n",
    "    * Great that this matches position/confidence\n",
    "    \n",
    "### vtti.head\\_rotation\\_~\\_baseline (where ~ is x, y, or z)\n",
    "* 14 values\n",
    "* BASELINE VARIES at same spots as head position baseline, so they are reset at the same time.\n",
    "    * For hypotheses about why resets happen, see vtti.head_position_~_baseline\n",
    "        \n",
    "### vtti.heading_gps\n",
    "* 1321 values\n",
    "    * Same frequency as elevation_gps (which is comforting)\n",
    "* Seems to be unnecessary, why do we need to know the direction of the car?\n",
    "\n",
    "### vtti.headlights\n",
    "* 543 values\n",
    "* All values are 1 or NaN\n",
    "    * -1: unavailable (vs nan??)\n",
    "    * 0: headlights off\n",
    "    * 1: headlights on\n",
    "* Might not be useful in these simulated driving situations (i.e. if a person who always puts headlights on tends to drive safer, that increased safety is tossed out the window when they begin to drive recklessly on purpose.\n",
    "\n",
    "### vtti.lane_distance_off_center\n",
    "* 13290 values\n",
    "* Ranges from ~-900 to ~700\n",
    "    * Standard deviation of 78, likely measured in cm then.\n",
    "    * Outliers may have to be removed (esp. around lane changes)\n",
    "        * May actually be helpful in identifying lane changes.\n",
    "\n",
    "### vtti.lane_width\n",
    "* 13099 values\n",
    "    * Strange that it is not the same as lane_distance_off_center (would assume these measurements come from the same peripheral.\n",
    "* Ranges from ~60 to ~750\n",
    "    * Average of 350, means this is likely in cm (assuming 10-12ft average lane width on a road.\n",
    "    \n",
    "\n",
    "### vtti.left_line_right_distance\n",
    "* 13269 values\n",
    "    * Strange that these all seem to vary.\n",
    "* Ranges from -970 to ~310\n",
    "    * Mean: -210, std: 90\n",
    "* Unsure what this measures, assuming it tells how close one side of the car is to one of the lines, but not sure which side and which line.\n",
    "    * May be very helpful to see how close the driver is willing to drive to the lines, shows recklessness.\n",
    "\n",
    "### vtti.(left/right)\\_marker_probability\n",
    "* 13290 values\n",
    "    * Same as lane distance off center at least\n",
    "* Ranges from 0 to 1024 (so this probability is recorded as a 10-bit value)\n",
    "* Allows us to discard data we are not certain about in the (left/right)\\_marker_type feature.\n",
    "\n",
    "### vtti.(left/right)\\_marker_type\n",
    "* 13290 values\n",
    "    * Same as a couple now, thankfully\n",
    "* Encoded as five distinct values: 0, 1, 2, 3, 4\n",
    "* Allows us to distinguish between legal/illegal turns as well as detect reckless behavior (crossing double yellows, crossing into the shoulder)\n",
    "\n",
    "### vtti.latitude / vtti.longitude\n",
    "* 1321 values \n",
    "    * Matches GPS data, suggesting this info was provided by the GPS\n",
    "* Hard to imagine how this will be useful besides comparing speed to speed limits on the same road.\n",
    "\n",
    "### vtti.light_level\n",
    "* 4029 values\n",
    "    * ~3x the rate of gps data\n",
    "* Ranges from 1 to 11.56\n",
    "* I believe this details the ambient lighting level, but at the time of writing cannot find the actual description of what this value represents.\n",
    "    * If this *is* ambient light, then could be useful to contrast the 'recklessness' of one's driving vs. the safety of the road at the time.\n",
    "    \n",
    "### vtti.month_gps/vtti.year_gps\n",
    "* 1321 values\n",
    "    * Same as other GPS records\n",
    "* Static values, no need to keep 1321 of them when one will do.\n",
    "* Provides very little information anyway\n",
    "\n",
    "### vtti.number_of_satellites\n",
    "* 1321 values\n",
    "    * Same as other GPS records\n",
    "* Ranges from 4 to 8 satellites at all times, with an average of 7.2 and an sd of .7.\n",
    "    * Implies very good GPS coverage for this trip (1308)\n",
    "        * This will not always be the case\n",
    "* This will need to be taken into consideration when using any of the GPS measures, as each additional satellite provides a significant increase in the accuracy of GPS measures.\n",
    "\n",
    "### vtti.odometer\n",
    "* 267 values\n",
    "    * Only 14 unique values\n",
    "        * Tells us this trip was ~13-15 miles\n",
    "* Very low density information, likely not useful in reality.\n",
    "\n",
    "### vtti.pdop\n",
    "* 1321 values\n",
    "    * Same frequency as GPS data (weirdly)\n",
    "* Not entirely sure what this measures\n",
    "* Ranges from 1.31 to 5.47, with a mean of 1.61 and an sd of 0.41\n",
    "    * Implies this value is generally low, with aberrant behavior being high values\n",
    "\n",
    "### vtti.pedal_brake_state\n",
    "* 13487 values\n",
    "    * Likely from bus of car\n",
    "* Ranges from 0 to 1\n",
    "    * Likely a percentage of how pressed down the brake pedal is at the present.\n",
    "* Very good measure of the intent of the driver in braking\n",
    "    * Allows us to detect hard braking behavior, and contrast this with earlier (and hence safer) braking\n",
    "\n",
    "### vtti.pedal_gas_position\n",
    "* 13487 values\n",
    "    * Likely from bus of car\n",
    "* Ranges from 0 to ~37\n",
    "    * Likely a measure of pressure on the gas pedal, has a granularity of 0.38\n",
    "        * Only 94 levels present, but a max of nearly 38 and a g of 0.38 implies that there are 100 possible levels for the gas pedal\n",
    "            * Likely unverifiable, instead we can simply use this data as a proportion of the maximum gas pedal pressure.\n",
    "* Very good measure of the intent of the driver in accelerating\n",
    "    * Allows us to detect aggressive accelerations and dangerous cornering, and to contrast these with safer behaviors\n",
    "\n",
    "### vtti.prndl\n",
    "* 13487 values\n",
    "* Direct encoding of Park, Reverse, Neutral, Drive, Lower\n",
    "    * Only values 0, 1, 2, 3 are present (4 unique values)\n",
    "        * My suspicion is that this is caused by the fact that no one ever puts their car into lower gears without hauling uphill.\n",
    "* Will be useful to split behaviors into dangerous *driving* behaviors, *reversing* behaviors, and possibly behaviors while in neutral\n",
    "\n",
    "### vtti.right_line_left_distance\n",
    "* 13283 values\n",
    "    * The fact that this number is different than the number of values we have for  the similarly named left_line_right_distance implies these are calculated values\n",
    "       * Does this mean we should associate/relatively trust it with the probabilities for line estimates?\n",
    "* Still not sure what these variables mean\n",
    "\n",
    "### vtti.seatbelt_driver\n",
    "* No non-NaN values present in file 1308\n",
    "    * Not even relevant anyway, since this training data does not include situations where the driver breaks the law (e.g. not wearing a seatbelt)\n",
    "\n",
    "### vtti.speed_gps\n",
    "* 1321 values\n",
    "    * Matches all other GPS values\n",
    "* Ranges from 0 to 106.5, mean of 35 and sd of 36\n",
    "    * Lots of variation, will be interesting to use this\n",
    "* May not be useful compared to other speed measures\n",
    "\n",
    "### vtti.speed_network\n",
    "* 12077\n",
    "    * Doesn't match any other known values, may be a sign of missing data in this\n",
    "        * Still likely more accurate than GPS data\n",
    "* Ranges from 0 to 108, mean of 36 and sd of 36\n",
    "    * Similar variation to GPS data\n",
    "\n",
    "### vtti.steering_wheel_position\n",
    "* 13486 values\n",
    "    * Likely from bus of car (off by 1 of other suspects for this)\n",
    "* Ranges from -320 to 433, mean of 27 and sd of 85\n",
    "    * Granularity of .125 suggests we could encode this more efficiently\n",
    "        * Would require *true* range of this feature\n",
    "* Can tell us how quickly the driver is turning the wheel. Sharper wheel turns associated with higher speeds imply hard turning/cornering (and therefore reckless behavior)\n",
    "\n",
    "\n",
    "### vtti.temperature_interior\n",
    "* 936 values, 142 unique, 0.00625 granularity\n",
    "* Ranges from ~28 to ~42, with a mean of 36 and an sd of 2.5\n",
    "\n",
    "### computed.time_bin\n",
    "* 1321 values\n",
    "    * Implies that this data is computed from GPS data\n",
    "* Only value is 6, so I'm not sure what this value represents.\n",
    "\n",
    "### vtti.traction_control_state\n",
    "* 13486 values\n",
    "    * Implies this data is taken from bus of car\n",
    "* All values are 0\n",
    "   * Regardless, this feature should be useful for event detection (hard cornering, hard acceleration)\n",
    "\n",
    "### vtti.turn_signal\n",
    "* No non-NaN values present in file 1308 or file 1229\n",
    "* This data would allow us to measure the safety of a drivers turning and lane-changing behaviors\n",
    "    * This would be very valuable information, but without turn signal data being present this will be hard.\n",
    "\n",
    "### vtti.video_frame\n",
    "* 13480 values\n",
    "    * Integer values, naturally\n",
    "* Each video frame seems to correspond to an observation\n",
    "* Allows us to easily check out events we detect in the sample video.\n",
    "\n",
    "### vtti.wiper\n",
    "* 543 values\n",
    "* All values for trip 1308 are 0\n",
    "* Allows us to detect (at the very least moderate-severe) rainy/snowy conditions without relying on extracting video data.\n",
    "\n",
    "### Vehicle tracking data:\n",
    "* Track1 is quite crowded, whereas others are not (seems obvious)\n",
    "* Data allows us to understand how many other drivers are around\n",
    "    * Dangerous behavior with others around is *even more* reckless, so this will be something to consider\n",
    "        * Also will be able to consider proximity, catchup behavior, following behavior (i.e. tailgating or not)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "\n",
    "This section of the notebook deals with cleaning the data based on observations made in the EDA section of this notebook. This will require smoothing of some variables, pruning of others, and "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning to be done:\n",
    "\n",
    "## High Priority\n",
    "* HIGH: Add smoothing of some sort (likely thresholding plus random variation) to clean the accelerometer, pedal, and speed behavior\n",
    "    * May be missing some categories\n",
    "\n",
    "\n",
    "## Medium Priority\n",
    "* MED: Remove any columns that are all nulls or all the same value.\n",
    "    * Save the singular value if it seems like it could be useful, else ignore it\n",
    "* MED: Write a function to call the google api for each Lat/Long and get the current speed limit\n",
    "    * Will need to be converted to the speed format used in speed_gps and speed_network\n",
    "    * Not really data cleaning, belongs in an external data notebook\n",
    "        * Could also use the following feature extraction notebooks:\n",
    "            * Event detection via csv\n",
    "            * Event detection via video\n",
    "            * Distraction detection via video\n",
    "                * From posture detection using OpenCV\n",
    "            * Distraction detection via csv\n",
    "                * From the head position and rotation data provided by vtti\n",
    "            * Braking behavior assessment via csv\n",
    "            * Acceleration behavior assessment via csv\n",
    "            * Following behavior assessment via csv\n",
    "            * Lane changing behavior assessment via csv\n",
    "            * Frequency domain conversion (for any time-series columns that are not already assessed broadly enough) via csv\n",
    "        * Also need a notebook for clustering 'sections' of driving (likely between full-stops)\n",
    "            * Will require converting time-series data to frequency data (as sections are of different length)\n",
    "                * This will have to be done in its own notebook\n",
    "\n",
    "\n",
    "## Low Priority\n",
    "* LOW: Any columns that have a non-real granularity should be converted to a space-saving format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TO_DROP = [\n",
    "    'vtti.file_id', # file id is in the name of the csv\n",
    "    'computed.day_of_month', # consistent throughout the entire csv. Verify this before dropping.\n",
    "    'computed.time_bin', # see ^\n",
    "    'vtti.month_gps', # see ^\n",
    "    'vtti.year_gps' # see ^\n",
    "] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\",\\t\".join(data.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
